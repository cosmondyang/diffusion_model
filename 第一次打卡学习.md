# diffusion model å­¦ä¹ 
-ç”»å›¾ä½œä¸šä¸¤ä¸ªå±•ç¤ºï¼š
-å…·ä½“ä»£ç å­¦ä¹ ï¼š
## è°ƒç”¨hugging faceç›¸å…³å­¦ä¹ èµ„æ–™ã€‚

- %pip install -qq -U diffusers datasets transformers accelerate ftfy pyarrow==9.0.0 install diffuser çš„library

## å®šä¹‰ä¸€äº›æœ‰ç”¨çš„functionè¿›è¡Œæ–¹ä¾¿ç”»å›¾ã€‚

```python
import numpy as np
import torch
import torch.nn.functional as F
from matplotlib import pyplot as plt
from PIL import Image


def show_images(x):
    """Given a batch of images x, make a grid and convert to PIL"""
    x = x * 0.5 + 0.5  # Map from (-1, 1) back to (0, 1)
    grid = torchvision.utils.make_grid(x)
    grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255
    grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))
    return grid_im


def make_grid(images, size=64):
    """Given a list of PIL images, stack them together into a line for easy viewing"""
    output_im = Image.new("RGB", (size * len(images), size))
    for i, im in enumerate(images):
        output_im.paste(im.resize((size, size)), (i * size, 0))
    return output_im
```

 Mac users may need device = 'mps' (untested)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
å…¶ä¸­show image ç”¨åˆ°çš„ PILä»€ä¹ˆæ„æ€ï¼ŒæŸ¥æ‰¾ï¼š
make_grid å°†æ‰€æœ‰imagesè¿›è¡Œå åŠ ã€‚

## ä»youtubeç§è¿›è¡Œvideoè°ƒç”¨ï¼š
from IPython.display import YouTubeVideo

YouTubeVideo("W4Mcuh38wyM")


## è°ƒç”¨è®­ç»ƒå¥½çš„pipelineã€‚
from diffusers import StableDiffusionPipeline

*Check out https://huggingface.co/sd-dreambooth-library for loads of models from the community
model_id = "sd-dreambooth-library/mr-potato-head"

*Load the pipeline
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(
    device
)

å½“è¿›è¡Œå®Œloadåï¼Œå¯ä»¥ç”¨ promptè¿›è¡Œæ¨¡å‹çš„ç”Ÿæˆã€‚
prompt = "an abstract oil painting of sks mr potato head by picasso"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]
image

## ä¸‰ä¸ªé‡ç‚¹éƒ¨åˆ†ï¼š
The core API of ğŸ¤— Diffusers is divided into three main components:

Pipelines: high-level classes designed to rapidly generate samples from popular trained diffusion models in a user-friendly fashion.
Models: popular architectures for training new diffusion models, e.g. UNet.
Schedulers: various techniques for generating images from noise during inference as well as to generate noisy images for training.

pipelineï¼š å°±æ˜¯æ¯”è¾ƒæœ‰åçš„è®­ç»ƒå¥½çš„æ•´ä¸ªmodelå’Œæµç¨‹ã€‚
modelï¼šä½¿ç”¨çš„æœ‰ç”¨çš„model structureï¼Œæ™®éç”¨æ¥trianä¸åŒçš„æ•°æ®ã€‚
schedulersï¼šæŠ€å·§ç”¨æ¥çœ‹noiseå’Œå»noiseé˜¶æ®µã€‚

